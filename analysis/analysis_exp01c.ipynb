{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abee5ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "twitter_datasetFolder = Path(\"../datasets/twitter\")\n",
    "exp01c_resultsFolder = Path(\"../experiments/exp01c/results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "922333b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "pd.set_option('display.max_columns', None)\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore')\n",
    "# Show all columns in a single line without wrapping\n",
    "pd.set_option('display.max_columns', None)\n",
    "# Also, make the display wider so it fits more\n",
    "pd.set_option('display.width', 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4ad16e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              tweet_id  class  error[Truncated axis]  error[Dual axis]  error[Value as area/volume]  error[Inverted axis]  error[Uneven binning]  error[Unclear encoding]  error[Inappropriate encoding]  error[Cherry-picking]  error[Setting an arbitrary threshold]  error[Causal inference]  error[Issues with data validity]  error[Failure to account for statistical nuance]  error[Misrepresentation of scientific studies]  error[Incorrect reading of chart]\n",
      "0  1220060594868555778      1                  False             False                         True                 False                  False                    False                          False                  False                                  False                    False                             False                                             False                                           False                              False\n",
      "1  1234688701114060800      1                  False             False                         True                 False                  False                    False                          False                  False                                  False                    False                             False                                             False                                           False                              False\n",
      "2  1236331391643779074      1                  False             False                        False                 False                  False                    False                          False                  False                                  False                     True                             False                                             False                                           False                              False\n",
      "3  1238453491917631489      1                  False             False                         True                 False                  False                    False                          False                  False                                  False                    False                             False                                             False                                           False                              False\n",
      "4  1239398342599364609      1                  False             False                         True                 False                  False                    False                          False                  False                                  False                    False                             False                                             False                                           False                              False\n"
     ]
    }
   ],
   "source": [
    "# load twitter dataset\n",
    "twitter_dataset = pd.read_csv(twitter_datasetFolder / \"index.csv\")\n",
    "# columns tweet_id must be loaded as string\n",
    "twitter_dataset[\"tweet_id\"] = twitter_dataset[\"tweet_id\"].astype(str)\n",
    "# map class column to 1 and 0\n",
    "twitter_dataset[\"class\"] = twitter_dataset[\"class\"].map({\"positive\": 1, \"negative\": 0})\n",
    "\n",
    "print(twitter_dataset.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d54b46c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model results: qwen2.5vl:72b -- 2336 tweets\n",
      "Loaded model results: gemma3:27b -- 2336 tweets\n"
     ]
    }
   ],
   "source": [
    "# load model results. structure: results[modelName][tweet_id] = result_dict\n",
    "results = {}\n",
    "\n",
    "for modelFolder in exp01c_resultsFolder.glob(\"*\"):\n",
    "    if not modelFolder.is_dir():\n",
    "        continue\n",
    "    modelName = modelFolder.name\n",
    "    results[modelName] = {}\n",
    "\n",
    "    for resultFile in modelFolder.glob(\"*.json\"):\n",
    "        with open(resultFile, \"r\") as f:\n",
    "            result = json.load(f)\n",
    "            twid = result[\"tweet_id\"]\n",
    "            results[modelName][twid] = result\n",
    "    print(f\"Loaded model results: {modelName} -- {len(results[modelName])} tweets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "795ddc0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Results RAW:\n",
      "              tweet_id  class  gemma3:27b  qwen2.5vl:72b\n",
      "0  1220060594868555778      1           1              1\n",
      "1  1234688701114060800      1           1              0\n",
      "2  1236331391643779074      1           1              1\n",
      "3  1238453491917631489      1           1              1\n",
      "4  1239398342599364609      1           1              1\n"
     ]
    }
   ],
   "source": [
    "# analysis of classification results\n",
    "df_classification = twitter_dataset.copy()[[\"tweet_id\", \"class\"]]\n",
    "\n",
    "\n",
    "for modelName in sorted(results.keys()):\n",
    "    df_classification.insert(len(df_classification.columns), modelName, 0)\n",
    "    for tweetId in results[modelName]:\n",
    "        result = results[modelName][tweetId]\n",
    "        isMisleading = result[\"response\"][\"is_misleading\"]\n",
    "        df_classification.loc[df_classification[\"tweet_id\"] == tweetId, modelName] = int(isMisleading)\n",
    "\n",
    "\n",
    "print(\"Classification Results RAW:\")\n",
    "print(df_classification.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54eff473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Summary of classification metrics:\n",
      "\n",
      "\n",
      "           model  accuracy  roc_auc  f1_macro  precision_macro  recall_macro  precision_NotMis  recall_NotMis  f1_NotMis  precision_Mis  recall_Mis  f1_Mis    TP   FP   FN   TN\n",
      "1  qwen2.5vl:72b     0.580    0.580     0.531            0.639         0.580             0.728          0.257       0.38          0.549       0.904   0.683  1056  868  112  300\n",
      "0     gemma3:27b     0.562    0.562     0.499            0.627         0.562             0.717          0.206       0.32          0.536       0.919   0.677  1073  927   95  241\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Detailed classification reports:\n",
      "\n",
      "\n",
      "Classification report for gemma3:27b:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "not-misleading      0.717     0.206     0.320      1168\n",
      "    misleading      0.536     0.919     0.677      1168\n",
      "\n",
      "      accuracy                          0.562      2336\n",
      "     macro avg      0.627     0.562     0.499      2336\n",
      "  weighted avg      0.627     0.562     0.499      2336\n",
      "\n",
      "\n",
      "ROC AUC score for gemma3:27b: 0.5625\n",
      "\n",
      "Confusion matrix for gemma3:27b:\n",
      "[[ 241  927]\n",
      " [  95 1073]]\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n",
      "Classification report for qwen2.5vl:72b:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "not-misleading      0.728     0.257     0.380      1168\n",
      "    misleading      0.549     0.904     0.683      1168\n",
      "\n",
      "      accuracy                          0.580      2336\n",
      "     macro avg      0.639     0.580     0.531      2336\n",
      "  weighted avg      0.639     0.580     0.531      2336\n",
      "\n",
      "\n",
      "ROC AUC score for qwen2.5vl:72b: 0.5804794520547945\n",
      "\n",
      "Confusion matrix for qwen2.5vl:72b:\n",
      "[[ 300  868]\n",
      " [ 112 1056]]\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, precision_score, recall_score,\n",
    "    roc_auc_score, confusion_matrix\n",
    ")\n",
    "import pandas as pd\n",
    "\n",
    "df = df_classification.copy()\n",
    "summary = []\n",
    "\n",
    "_ROUNDING = 3  # decimal places for rounding metrics\n",
    "\n",
    "for modelName in sorted(results.keys()):\n",
    "    y_true = df[\"class\"].astype(int)\n",
    "    y_pred = df[modelName].astype(int)\n",
    "\n",
    "    # Main metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    roc_auc = roc_auc_score(y_true, y_pred)\n",
    "    \n",
    "    # Macro averages (treat both classes equally)\n",
    "    f1_macro = f1_score(y_true, y_pred, average=\"macro\")\n",
    "    precision_macro = precision_score(y_true, y_pred, average=\"macro\")\n",
    "    recall_macro = recall_score(y_true, y_pred, average=\"macro\")\n",
    "    \n",
    "\n",
    "    # Per-class metrics\n",
    "    precision_0 = precision_score(y_true, y_pred, pos_label=0)\n",
    "    recall_0 = recall_score(y_true, y_pred, pos_label=0)\n",
    "    f1_0 = f1_score(y_true, y_pred, pos_label=0)\n",
    "\n",
    "    precision_1 = precision_score(y_true, y_pred, pos_label=1)\n",
    "    recall_1 = recall_score(y_true, y_pred, pos_label=1)\n",
    "    f1_1 = f1_score(y_true, y_pred, pos_label=1)\n",
    "\n",
    "    # Confusion matrix components\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "\n",
    "    summary.append({\n",
    "        \"model\": modelName,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"roc_auc\": roc_auc,\n",
    "        \"f1_macro\": f1_macro,\n",
    "        \"precision_macro\": precision_macro,\n",
    "        \"recall_macro\": recall_macro,\n",
    "        \"precision_NotMis\": precision_0,\n",
    "        \"recall_NotMis\": recall_0,\n",
    "        \"f1_NotMis\": f1_0,\n",
    "        \"precision_Mis\": precision_1,\n",
    "        \"recall_Mis\": recall_1,\n",
    "        \"f1_Mis\": f1_1,\n",
    "        \"TP\": tp,\n",
    "        \"FP\": fp,\n",
    "        \"FN\": fn,\n",
    "        \"TN\": tn\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary).round(_ROUNDING)\n",
    "summary_df = summary_df.sort_values(by=\"roc_auc\", ascending=False)\n",
    "\n",
    "print(\"\\n\\nSummary of classification metrics:\\n\\n\")\n",
    "\n",
    "print(summary_df)\n",
    "\n",
    "print(\"\\n\\n--------------------------------------------------\\n\\n\")\n",
    "print(\"Detailed classification reports:\\n\\n\")\n",
    "\n",
    "for modelName in sorted(results.keys()):\n",
    "    y_true = df[\"class\"]\n",
    "    y_pred = df[modelName]\n",
    "\n",
    "    print(f\"Classification report for {modelName}:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=[\"not-misleading\", \"misleading\"], digits=_ROUNDING))\n",
    "    \n",
    "    roc_auc = roc_auc_score(y_true, y_pred)\n",
    "    print(f\"\\nROC AUC score for {modelName}: {roc_auc}\\n\")\n",
    "\n",
    "    print(f\"Confusion matrix for {modelName}:\")\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    \n",
    "    print(\"\\n\\n--------------------------------------------------\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29222579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subtable:\n",
      "           model  accuracy    TP   FP   FN   TN\n",
      "1  qwen2.5vl:72b     0.580  1056  868  112  300\n",
      "0     gemma3:27b     0.562  1073  927   95  241\n"
     ]
    }
   ],
   "source": [
    "# model  accuracy    TP   FP   FN   TN\n",
    "# generate a subtable\n",
    "\n",
    "subtable = summary_df[[\"model\", \"accuracy\", \"TP\", \"FP\", \"FN\", \"TN\"]]\n",
    "print(\"Subtable:\")\n",
    "print(subtable)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
